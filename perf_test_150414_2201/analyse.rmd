Analysis of Tabarnac optimization on IS
=======================================


```{r parsing ,echo=F}
library(ggplot2)
library(plyr)
data<-data.frame(read.csv2(file="results.csv",sep=',',dec='.'))
#str(data)
#show(data)
```
Experiment executed the 15/03/2015 on turing (UFRGS).

Setup
-----

Optimizations:

+ Dynamic: threads use OpenMP schedule(dynamic), default configuration for IS
+ Cyclic:  thread use a static schedule with a step of size 1
+ Tabarnac: cyclic configuration taking into account the Gaussian use of key_buff1
+ libnuma: tabarnac opti + mapping using libnuma


Execution type:

+ base: no tool used for mapping (first touch)
+ numbalance: use kernel.numa_balancing


Expectations
------------

The parallel part of IS is small, so numa balancing might not be efficient
(cost of the overhead).
Tabarnac should be good even with first touch as exclusivity is very high and
there is no "one thread" initialization.
If libnuma isn't the best Optimization, maybe there is a problem in my code
...

Results
-------

###   Execution time

```{r ExecTime, echo=F}
stat<-ddply(data,c("Runtime","Opti"),summarise,
            N=length(Time),mean=mean(Time),sd=sd(Time),se=sd/sqrt(N))
stat <- subset(stat, stat$Opti!="libnuma")
p<-ggplot(stat,aes(x=Runtime,y=mean, fill=Opti))
p  <-  p + geom_bar(stat="identity", position=position_dodge(.9) )
p  <-  p + geom_errorbar(aes(ymin=mean-se, ymax=mean+se),
                  width=.2,                    # Width of the error bars
                  position=position_dodge(.9))
p <- p + xlab("Execution type")
p <- p + ylab("Time (s)")
#p <- p + ggtitle("Execution time of matrix multiplication")
p <- p + guides(fill=guide_legend(title="Optimization"))
# BW theme
p <- p + theme_bw()
p <-  p + theme(panel.grid.minor = element_line(colour = "black", linetype="dashed", size = 0.1),
        panel.grid.major = element_line(colour = "black", size = 0.1))
p <- p + scale_fill_grey()
p <- p + theme(legend.position="bottom")
show(p)
ggsave("figure/ExecutionTime.pdf", width=10, height=10)
```

Detailled Values:

```{r DetailledValues, echo=F}
show(stat)
```

### SpeedUp

```{r Speedup, echo=F}
stat1 <- subset(stat, stat$Runtime=="numabalance")
speedup <- c("numabalance", as.character(stat1[which.min(stat1$mean),]$Opti),
             stat1[stat1$Opti=="dynamic",]$mean / min(stat1$mean))
stat1 <- subset(stat, stat$Runtime=="base")
speedup <- rbind(speedup, c("base", as.character(stat[which.min(stat1$mean),]$Opti),
                stat1[stat1$Opti=="dynamic",]$mean / min(stat1$mean)))
speedup <- data.frame(speedup)
colnames(speedup) <- c("Runtime",  "Opti", "Val")
p<-ggplot(speedup,aes(x=Runtime,y=Val, fill=Opti))
p  <-  p + geom_bar(stat="identity", position=position_dodge(.9) )
p <- p + xlab("Execution type")
p <- p + ylab("Best SpeedUp")
p <- p + ggtitle("Best Speedup for matrix multiplications")
# BW theme
p <- p + guides(fill=guide_legend(title="Optimization"))
p <- p + theme_bw()
p <-  p + theme(panel.grid.minor = element_line(colour = "black", linetype="dashed", size = 0.1),
        panel.grid.major = element_line(colour = "black", size = 0.1))
p <- p + scale_fill_grey() #breaks=c(4,2))
p <- p + theme(legend.position="bottom")
show(p)
ggsave("figure/speedup.pdf", width=10, height=10)
```

Conclusions
-----------

Tabarnac is always the most efficient and numa balancing is not required as
its overhead is high (?).

There must be a problem with my libnuma code, should be the same as tabarnac.


```{r free, echo=F}
remove(p)
remove(stat)
remove(data)
remove(speedup)
remove(stat1)
```
